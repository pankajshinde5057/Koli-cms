<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Face Recognition</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            -webkit-tap-highlight-color: transparent;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: #000;
            color: white;
            height: 100vh;
            overflow: hidden;
            position: relative;
        }

        #video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            z-index: 1;
        }

        #canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 2;
            pointer-events: none;
        }

        .toast-container {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            height: 100%;
            display: flex;
            align-items: flex-end;
            justify-content: center;
            pointer-events: none;
            z-index: 1000;
        }

        .toast {
            background: rgba(0, 0, 0, 0.85);
            color: white;
            padding: 16px 30px;
            border-radius: 50px;
            box-shadow: 0 5px 25px rgba(0, 0, 0, 0.3);
            opacity: 0;
            transform: translateY(100vh);
            transition: all 0.6s cubic-bezier(0.68, -0.55, 0.27, 1.55);
            display: flex;
            align-items: center;
            gap: 12px;
            max-width: 80%;
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
            position: relative;
            overflow: hidden;
        }

        .toast.show {
            opacity: 1;
            transform: translateY(-50vh);
        }

        .toast.hide {
            opacity: 0;
            transform: translateY(100vh);
        }

        .toast.success {
            background: rgba(34, 197, 94);
            color: #000;
        }

        .toast.error {
            background: rgba(239, 68, 68, 0.9);
        }

        .toast.info {
            background: rgba(59, 130, 246, 0.9);
        }
        .toast.warning {
            background-color: yellow;
            color: #000;
        }

        .toast-timer {
            position: absolute;
            bottom: 0;
            left: 0;
            height: 4px;
            background: rgba(255, 255, 255, 0.5);
            width: 100%;
            transform-origin: left;
        }

        .status-indicator {
            position: absolute;
            top: 20px;
            left: 0;
            right: 0;
            text-align: center;
            z-index: 4;
            font-size: 14px;
            color: rgba(255, 255, 255, 0.8);
            text-shadow: 0 1px 3px rgba(0, 0, 0, 0.5);
            padding: 8px 16px;
            background: rgba(0, 0, 0, 0.4);
            backdrop-filter: blur(5px);
            -webkit-backdrop-filter: blur(5px);
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        .instructions {
            position: absolute;
            bottom: 20px;
            left: 0;
            right: 0;
            text-align: center;
            z-index: 4;
            font-size: 14px;
            color: rgba(255, 255, 255, 0.9);
            padding: 0 20px;
            font-weight: 500;
        }

        .cooldown-overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.7);
            z-index: 10;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            opacity: 0;
            pointer-events: none;
            transition: opacity 0.5s ease;
        }

        .cooldown-overlay.active {
            opacity: 1;
            pointer-events: all;
        }

        .cooldown-text {
            font-size: 24px;
            margin-bottom: 20px;
            text-align: center;
            color: white;
        }

        .cooldown-count {
            font-size: 48px;
            font-weight: bold;
            color: #00ffcc;
            text-shadow: 0 0 10px rgba(0, 255, 204, 0.5);
        }

        .pulse {
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% { opacity: 0.6; }
            50% { opacity: 1; }
            100% { opacity: 0.6; }
        }

        @media (max-width: 768px) {
            .toast {
                padding: 14px 24px;
                font-size: 14px;
            }

            .cooldown-text {
                font-size: 20px;
            }

            .cooldown-count {
                font-size: 36px;
            }

            .instructions {
                font-size: 13px;
            }
        }

        @media (max-width: 480px) {
            .toast {
                padding: 12px;
                font-size: 17px;
                max-width: 90%;
            }

            .cooldown-text {
                font-size: 22px;
            }

            .cooldown-count {
                font-size: 32px;
            }

            .instructions {
                font-size: 16px;
                font-weight: 600;
                color: rgba(255, 255, 255, 1);
            }

            .status-indicator {
                font-size: 16px;
                padding: 6px 12px;
            }
        }

        @media (max-height: 600px) {
            .instructions {
                bottom: 10px;
            }
        }
    </style>
</head>
<body>
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>

    <div class="status-indicator" role="status" aria-live="polite">Initializing camera...</div>

    <div class="toast-container">
        <div class="toast" id="toast" role="alert" aria-live="assertive">
            <div class="toast-timer" id="toastTimer"></div>
        </div>
    </div>

    <div class="instructions">Position your face in the center</div>

    <div class="cooldown-overlay" id="cooldownOverlay">
        <div class="cooldown-text">Recognition complete</div>
        <div class="cooldown-count" id="cooldownCount">5</div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
    <script src="https://cdn.jsdelivr.net/npm/canvas-confetti@1.9.3/dist/confetti.browser.min.js"></script>

    <script>
        // DOM elements
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const toast = document.getElementById('toast');
        const toastTimer = document.getElementById('toastTimer');
        const statusIndicator = document.querySelector('.status-indicator');
        const cooldownOverlay = document.getElementById('cooldownOverlay');
        const cooldownCount = document.getElementById('cooldownCount');

        // State variables
        let model = null;
        let isRecognizing = false;
        let cooldownActive = false;
        let lastRecognizedName = '';
        let toastTimeout = null;
        let lastFacePosition = null;
        let detectionPaused = false;
        let faceCenteredFrames = 0;
        const REQUIRED_CENTERED_FRAMES = 30; // Approx 0.5s at 60fps

        // API Endpoints
        const RECOGNIZE_API = '{{ FASTAPI_FACE_URL }}/recognize/';
        const ATTENDANCE_API = '{{ OUR_DOMAIN }}/mark_attendace/';

        // Get known faces from Django context
        const knownFaces = JSON.parse('{{ known_faces_json|escapejs }}');

        // Callback functions for recognition results
        function onFirstRecognation(name) {
            lastRecognizedName = name;
            showToast(`Welcome, ${name}!`, 'success', 3);

            // Celebration animation for first-time recognition
            if (typeof confetti !== 'undefined' && lastFacePosition) {
                const start = lastFacePosition.topLeft;
                const end = lastFacePosition.bottomRight;
                const centerX = (start[0] + end[0]) / 2 / canvas.width;
                const centerY = (start[1] + end[1]) / 2 / canvas.height;

                confetti({
                    particleCount: 150,
                    spread: 70,
                    origin: { x: centerX, y: centerY },
                    colors: ['#bb0000', '#ffffff', '#00bb00', '#0000bb', '#ffff00', '#ff00ff']
                });
            }

            startCooldown();
        }

        function onAlreadyClockedIn(name) {
            lastRecognizedName = name;
            showToast(`${name}, you are already clocked-In`, 'warning', 5);
            startCooldown();
        }

        function onRecognitionError(message) {
            isRecognizing = false;
            showToast(`${message}`, 'error', 5);
            startCooldown();
        }

        // Capture and send face image for recognition
        async function captureAndSend() {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            
            canvas.toBlob(async (blob) => {
                try {
                    const formData = new FormData();
                    formData.append('face_image', blob, 'face.jpg');
                    formData.append('known_faces', JSON.stringify(knownFaces));
                    
                    const recognizeResponse = await fetch(RECOGNIZE_API, {
                        method: 'POST',
                        body: formData
                    });

                    const recognizeData = await recognizeResponse.json();

                    if (recognizeData.status === 'success') {
                        const attendanceResponse = await fetch(ATTENDANCE_API, {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'application/json'
                            },
                            body: JSON.stringify({
                                employee_id: recognizeData.results[0].user.employee_id,
                                name: recognizeData.results[0].user.name
                            })
                        });
                        const attendanceData = await attendanceResponse.json();

                        if (attendanceData.status == 'first recognized') {
                            onFirstRecognation(attendanceData.user.name);
                        } else if (attendanceData.status === 'already clockin') {
                            onAlreadyClockedIn(attendanceData.user.name);
                        } else {
                            onRecognitionError(attendanceData.message);
                        }
                    } else {
                        onRecognitionError('Face Not in Our System');
                    }
                } catch (err) {
                    onRecognitionError('Face Not in Our System');
                }
            }, 'image/jpeg');
        }

        // Initialize the application
        async function init() {
            showToast('Initializing face recognition...', 'info', 5);
            statusIndicator.textContent = "Loading KOLI's Face Recognation System...";

            try {
                // Load the Blazeface model
                model = await blazeface.load();
                showToast('System ready', 'success', 5);
                statusIndicator.textContent = 'starting camera...';

                // Start the camera
                await startCamera();

                // Adjust canvas size to match video
                video.addEventListener('loadeddata', () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    statusIndicator.textContent = 'Camera active, detecting faces...';

                    // Start detection loop
                    detectFaces();
                });
            } catch (error) {
                console.error('Error initializing:', error);
                statusIndicator.textContent = `Error: ${error.message}`;
                showToast(`Failed to initialize system: ${error.message}`, 'error', 5);
            }
        }

        // Start the camera with dynamic resolution
        async function startCamera() {
            try {
                // Determine resolution based on screen size
                const isMobile = window.innerWidth <= 768;
                const constraints = {
                    video: {
                        width: { ideal: isMobile ? 640 : 1280 },
                        height: { ideal: isMobile ? 480 : 720 },
                        facingMode: 'user'
                    }
                };
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
            } catch (error) {
                console.error('Error accessing camera:', error);
                statusIndicator.textContent = `Camera error: ${error.message}`;
                showToast('Camera access denied. Please enable camera permissions.', 'error', 5);
                throw error;
            }
        }

        // Check if face is centered and sufficiently large
        function isFaceCentered(prediction) {
            const start = prediction.topLeft;
            const end = prediction.bottomRight;
            const faceWidth = end[0] - start[0];
            const faceHeight = end[1] - start[1];
            const centerX = start[0] + faceWidth / 2;
            const centerY = start[1] + faceHeight / 2;

            // Video dimensions
            const videoWidth = video.videoWidth;
            const videoHeight = video.videoHeight;

            // Minimum face size (e.g., 20% of video width)
            const minFaceWidth = videoWidth * 0.2;
            const minFaceHeight = videoHeight * 0.2;

            // Acceptable center region (30% of video dimensions around the center)
            const centerRegionX = videoWidth * 0.3;
            const centerRegionY = videoHeight * 0.3;
            const videoCenterX = videoWidth / 2;
            const videoCenterY = videoHeight / 2;

            // Check if face is large enough
            if (faceWidth < minFaceWidth || faceHeight < minFaceHeight) {
                return false;
            }

            // Check if face center is within the acceptable region
            const isCentered = Math.abs(centerX - videoCenterX) < centerRegionX / 2 &&
                             Math.abs(centerY - videoCenterY) < centerRegionY / 2;

            return isCentered;
        }

        // Detect faces in the video frame
        async function detectFaces() {
            if (!model || cooldownActive || detectionPaused) {
                requestAnimationFrame(detectFaces);
                return;
            }

            try {
                // Perform face detection
                const predictions = await model.estimateFaces(video, false);

                // Clear canvas
                ctx.clearRect(0, 0, canvas.width, canvas.height);

                if (predictions.length > 0) {
                    // Store the face position
                    lastFacePosition = predictions[0];

                    // Draw face net on canvas
                    drawFaceNet(predictions[0]);

                    // Check if face is centered
                    if (isFaceCentered(predictions[0])) {
                        faceCenteredFrames++;
                        statusIndicator.textContent = 'Verifying...';
                        
                        // Wait for consistent centered face for ~0.5s
                        if (faceCenteredFrames >= REQUIRED_CENTERED_FRAMES && !isRecognizing && !cooldownActive) {
                            isRecognizing = true;
                            statusIndicator.textContent = 'Face detected. Recognizing...';
                            await captureAndSend();
                        }
                    } else {
                        faceCenteredFrames = 0;
                        isRecognizing = false;
                        statusIndicator.textContent = 'Please center your face';
                    }
                } else {
                    faceCenteredFrames = 0;
                    isRecognizing = false;
                    statusIndicator.textContent = 'Looking for faces...';
                    lastFacePosition = null;
                }
            } catch (error) {
                console.error('Error detecting faces:', error);
                showToast('Error detecting faces', 'error', 3);
            }

            // Continue detection
            requestAnimationFrame(detectFaces);
        }

        // Draw face net on canvas
        function drawFaceNet(prediction) {
            const start = prediction.topLeft;
            const end = prediction.bottomRight;
            const size = [end[0] - 120, end[1] - 120];

            // Calculate position and size
            const centerX = start[0] + size[0] / 3;
            const centerY = start[1] + size[1] / 3;
            const radiusX = size[0] / 2;
            const radiusY = size[1] / 2;

            // Calculate dynamic circle radius (5% of face width, clamped between 10 and 20 pixels)
            const circleRadius = Math.min(Math.max(size[0] * 0.05, 10), 20);

            // Draw oval outline
            ctx.beginPath();
            ctx.strokeStyle = isFaceCentered(prediction) ? 'rgba(255, 255, 255, 0.3)' : 'rgba(255, 255, 255, 0.1)';
            ctx.lineWidth = 2;
            ctx.ellipse(centerX, centerY, radiusX * 1.1, radiusY * 1.1, 0, 0, Math.PI * 2);
            ctx.stroke();

            // Draw circles around the face
            for (let i = 0; i < 8; i++) {
                const angle = (i / 8) * Math.PI * 2;
                const x = centerX + Math.cos(angle) * radiusX * 1.1;
                const y = centerY + Math.sin(angle) * radiusY * 1.1;

                ctx.beginPath();
                ctx.arc(x, y, circleRadius, 0, Math.PI * 2);
                ctx.fillStyle = isFaceCentered(prediction) ? 'rgba(0, 255, 204, 0.01)' : 'rgba(0, 255, 204, 0.01)';
                ctx.fill();
                ctx.strokeStyle = isFaceCentered(prediction) ? 'rgba(0, 255, 204, 0.1)' : 'rgba(0, 255, 204, 0.01)';
                ctx.stroke();
            }

            // Draw horizontal lines
            for (let i = 1; i <= 3; i++) {
                const y = start[1] + (size[1] * i / 4);
                ctx.beginPath();
                ctx.moveTo(centerX - radiusX * 1.1, y);
                ctx.lineTo(centerX + radiusX * 1.1, y);
                ctx.strokeStyle = isFaceCentered(prediction) ? 'rgba(255,255,255,0.3)' : 'rgba(255,255,255,0.3)';
                ctx.stroke();
            }

            // Draw vertical lines
            for (let i = 1; i <= 3; i++) {
                const x = start[0] + (size[0] * i / 4);
                ctx.beginPath();
                ctx.moveTo(x, centerY - radiusY * 1.1);
                ctx.lineTo(x, centerY + radiusY * 1.1);
                ctx.strokeStyle = isFaceCentered(prediction) ? 'rgba(255, 255, 255, 0.3)' : 'rgba(255, 255, 255, 0.3)';
                ctx.stroke();
            }
        }

        // Start cooldown period
        function startCooldown() {
            cooldownActive = true;
            isRecognizing = false;
            faceCenteredFrames = 0;

            // Show cooldown overlay
            cooldownOverlay.classList.add('active');

            let count = 5;
            cooldownCount.textContent = count;

            const countdown = setInterval(() => {
                count--;
                cooldownCount.textContent = count;

                if (count <= 0) {
                    clearInterval(countdown);
                    endCooldown();
                }
            }, 1000);
        }

        // End cooldown period
        function endCooldown() {
            cooldownOverlay.classList.remove('active');
            cooldownActive = false;

            // Hide toast and show ready message
            toast.classList.remove('show');
            toast.classList.add('hide');
            setTimeout(() => {
                toast.classList.remove('hide');
                showToast('Ready for next recognition', 'info', 3);
                statusIndicator.textContent = 'Looking for faces...';
            }, 600); // Match CSS transition duration
        }

        // Show toast notification with timer
        function showToast(message, type = 'info', duration = 3) {
            if (toastTimeout) {
                clearTimeout(toastTimeout);
                toast.classList.remove('show');
                toast.classList.add('hide');
                setTimeout(() => {
                    toast.classList.remove('hide');
                    updateToast(message, type, duration);
                }, 600); // Match CSS transition duration
            } else {
                updateToast(message, type, duration);
            }
        }

        // Update toast content and show
        function updateToast(message, type, duration) {
            toast.textContent = message;
            toast.className = `toast ${type}`;
            toast.setAttribute('aria-label', message);

            toastTimer.style.transition = 'none';
            toastTimer.style.width = '100%';
            toastTimer.offsetHeight;
            toastTimer.style.transition = `width ${duration}s linear`;
            toastTimer.style.width = '0%';

            toast.classList.add('show');

            toastTimeout = setTimeout(() => {
                toast.classList.remove('show');
                toast.classList.add('hide');
                setTimeout(() => {
                    toast.classList.remove('hide');
                }, 600); // Match CSS transition duration
            }, duration * 1000);
        }

        // Pause detection when app is in background
        document.addEventListener('visibilitychange', () => {
            detectionPaused = document.hidden;
            if (detectionPaused) {
                statusIndicator.textContent = 'App paused';
            } else {
                statusIndicator.textContent = 'Looking for faces...';
            }
        });

        // Initialize when page loads
        window.addEventListener('load', init);

        // Handle orientation changes
        window.addEventListener('orientationchange', () => {
            setTimeout(() => {
                if (video.srcObject) {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    if (lastFacePosition) {
                        drawFaceNet(lastFacePosition);
                    }
                }
            }, 300);
        });
    </script>
</body>
</html>